{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Waldo \n",
    "\n",
    "## Group members\n",
    "\n",
    "- Lillian Wood\n",
    "- Taha Alam\n",
    "- Zichen ‘Cardiff’ Jiang\n",
    "- Will Lutz\n",
    "- Sara Shao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In our project, we will perform PCA analysis on images of the character, Waldo, from Where’s Waldo to identify whether or not a test image is a picture of Waldo.\n",
    "\n",
    "Utilizing a dataset of black and white images of Waldo, we will reduce the dimensionality of the vectorized images by calculating the eigenvalues and eigenvectors of the original image to reconstruct an image of Waldo in a smaller subspace. Once the eigenface is constructed using x number of principal components, we will be able to calculate the Euclidean distance between this constructed image and test images of both Waldo and non-Waldo projected into the same subspace to identify if the image is a picture of Waldo. The goal of this project is to elaborate on the topic of PCA that was discussed in class and present it in a fun and interactive way.\n",
    "\n",
    "This project is important because finding Waldo manually is extremely tricky and time-consuming, sometimes ranging. Therefore, this intuitive PCA method to automatically find Waldo is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Work\n",
    "\n",
    "Our project is based on the PCA example presented in class and in the homework. We will take the same steps to create the eigenfaces of our training and test sets of images. Once we create the eigenfaces for Waldo, we will follow the methods described in Liton Chandra Paul and Abdulla Al Sumam (2012) <a name=\"relatedwork\"></a> [1](#relatedwork) in order to calculate the distance between the eigenfaces of the test images and the eigenfaces of the training images when projected into the subspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Briefly, we collected 22 Waldo images, randomly vectorize 21 of them, and put these 21 vectors into a matrix. PCA will be done using these 21 images. The 22nd Waldo image will be used to test whether our eigenfaces can reconstruct this new image. Lastly, we tested our eigenfaces on a whole puzzle by breaking down the puzzle image to little square boxes and finding the box that has Waldo's face in it through reconstruction distance calculation.\n",
    "\n",
    "### Collecting images\n",
    "We collected images from various sources, including https://www.localguidesconnect.com/t5/General-Discussion/Alert-Answers-included-Waldo-Answers-if-you-guys-are-struggling/td-p/722677, https://petitefoxdesigns.wordpress.com/2015/11/05/wheres-waldo-wednesday-in-town/, https://github.com/wirooo/FolloWaldo, and so on. We whimsically selected some images from these websites, downloaded them, and manually croped them to a square where the tip of Waldo's right ear and Waldo's left cheekbone are roughly aligned at the same coordinates across cropped images. These images are named 1 to 22.jpg in `waldo_manual/`.\n",
    "\n",
    "### Vectorizing Images\n",
    "Each manually cropped images that roughly align with each other are of different pixel sizes. So we used `myimage.resize((x, x))` to resize each image to the same dimension so that the column vector representation of each image has the same size. 21 of the 22 Waldo images are used to form the input matrix that will be used to generate our eigenfaces.\n",
    "\n",
    "### PCA\n",
    "Explaination\n",
    "\n",
    "### Reconstruction Distance Function\n",
    "Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Results - What did you discover? How well did it work?  As this is a class project, it is likely that many things did not work as well as planned.  For this project, detailing what went wrong is as important as describing what went well.  (approx 7 points)\n",
    "\n",
    "### Preparing the images\n",
    "\n",
    "vectorizing images explanation and code below"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 204,
=======
   "execution_count": 1,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "from PIL import Image\n",
    "import random\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 205,
=======
   "execution_count": 2,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. waldo_matrix = vectorize(100, 21, 'waldo_manual')\n",
    "# For the 22 Waldo pictures, 21 of them are turned into a 30000 by 1 (100 pixel x 100 pixel x 3) column vector. So each col of this 40000 by 21 matrix is one of the pictures.\n",
    "def vectorize(pixel, pic_num, pic_dir):\n",
    "    pic_dim = pixel * pixel * 3\n",
    "    A = np.empty([pic_dim, pic_num])\n",
    "\n",
    "    file_ls = []\n",
    "    for filename in os.listdir(pic_dir):\n",
    "        f = os.path.join(pic_dir, filename)\n",
    "        file_ls.append(f)\n",
    "\n",
    "    new_image_i = random.randrange(pic_num)\n",
    "    for i in range(len(file_ls)-1):\n",
    "        if i == new_image_i:\n",
    "            continue\n",
    "        else:\n",
    "            f = file_ls[i]\n",
    "            print(f)\n",
    "            img = Image.open(f).convert('RGB')\n",
    "            img_resized = img.resize((100, 100))\n",
    "            arr = np.array(img_resized)\n",
    "            flat_arr = arr.ravel()\n",
    "            v = np.matrix(flat_arr)\n",
    "            col_v = v.T\n",
    "            A[:, i][:, np.newaxis] = col_v\n",
    "            i += 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 206,
=======
   "execution_count": 3,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. viewimage(waldo_input[:, 8], pixel)\n",
    "def viewimage(vector, pixel):\n",
    "    # Showing the 8th picture from the matrix\n",
    "    vector_uint8 = vector.astype(np.uint8)\n",
    "    shape = (pixel, pixel, 3)\n",
    "    reconstruct_arr = np.asarray(vector_uint8).reshape(shape)\n",
    "    reconstruct_img = Image.fromarray(reconstruct_arr, 'RGB')\n",
    "    reconstruct_img.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 207,
=======
   "execution_count": 4,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waldo_manual/8.jpg\n",
      "waldo_manual/9.jpg\n",
      "waldo_manual/14.jpg\n",
      "waldo_manual/15.jpg\n",
      "waldo_manual/17.jpg\n",
      "waldo_manual/16.jpg\n",
      "waldo_manual/12.jpg\n",
      "waldo_manual/13.jpg\n",
      "waldo_manual/11.jpg\n",
      "waldo_manual/10.jpg\n",
      "waldo_manual/20.jpg\n",
      "waldo_manual/22.jpg\n",
      "waldo_manual/18.jpg\n",
      "waldo_manual/19.jpg\n",
      "waldo_manual/4.jpg\n",
      "waldo_manual/5.jpg\n",
      "waldo_manual/7.jpg\n",
      "waldo_manual/6.jpg\n",
      "waldo_manual/2.jpg\n",
      "waldo_manual/3.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 21)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 207,
=======
     "execution_count": 4,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = vectorize(100, 21, 'waldo_manual')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 208,
=======
   "execution_count": 5,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "viewimage(data[:, 0][:, np.newaxis], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "PCA explanation and code below"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 209,
=======
   "execution_count": 6,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigsort(V, eigvals):\n",
    "    \n",
    "    # Sort the eigenvalues from largest to smallest. Store the sorted\n",
    "    # eigenvalues in the column vector lambd.\n",
    "    lohival = np.sort(eigvals)\n",
    "    lohiindex = np.argsort(eigvals)\n",
    "    lambd = np.flip(lohival)\n",
    "    index = np.flip(lohiindex)\n",
    "    Dsort = np.diag(lambd)\n",
    "    \n",
    "    # Sort eigenvectors to correspond to the ordered eigenvalues. Store sorted\n",
    "    # eigenvectors as columns of the matrix vsort.\n",
    "    M = np.size(lambd)\n",
    "    Vsort = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        Vsort[:,i] = V[:,index[i]]\n",
    "    return Vsort, Dsort\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 210,
=======
   "execution_count": 7,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "# normc(M) normalizes the columns of M to a length of 1.\n",
    "def normc(Mat):\n",
    "    return normalize(Mat, norm='l2', axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 211,
=======
   "execution_count": 8,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[143.70521542],\n",
       "       [151.16099773],\n",
       "       [117.85941043],\n",
       "       ...,\n",
       "       [168.55102041],\n",
       "       [140.12018141],\n",
       "       [129.33560091]])"
      ]
     },
     "execution_count": 211,
=======
       "array([[139.76190476],\n",
       "       [152.42857143],\n",
       "       [116.57142857],\n",
       "       ...,\n",
       "       [124.38095238],\n",
       "       [113.76190476],\n",
       "       [242.85714286]])"
      ]
     },
     "execution_count": 8,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanface = np.mean(data, axis=1)\n",
    "meanface = meanface[:, np.newaxis]\n",
    "meanface"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 212,
=======
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewimage(meanface,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 21)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 212,
=======
     "execution_count": 9,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.matlib.repmat(meanface, 1, 21)).shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 213,
=======
   "execution_count": 10,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 21)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 213,
=======
     "execution_count": 10,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract the mean from all of the data (using the command numpy.matlib.repmat), and call the matrix of mean-subtracted data A"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
=======
   "execution_count": 11,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data - np.matlib.repmat(meanface, 1, 21)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 215,
=======
   "execution_count": 12,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, Vold = np.linalg.eig(A.T.dot(A))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 216,
=======
   "execution_count": 13,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "V, D = eigsort(Vold, eigvals)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 21)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
=======
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 21)\n"
     ]
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
    }
   ],
   "source": [
    "U = A.dot(V)\n",
    "#then normalize\n",
    "U = normc(U)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 218,
=======
   "execution_count": 15,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "C = U.T.dot(data - meanface)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewimage(data[:, i][:, np.newaxis], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
=======
   "execution_count": 20,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(21, 1)"
      ]
     },
     "execution_count": 221,
=======
       "array([  -34.74875761, -1525.57398207,  1904.85042157, -2575.96203892,\n",
       "        6740.26269398,  1676.62224551,  1745.9875286 ,  6366.59393501,\n",
       "       -4157.39859469,  4737.85303803,  1208.79092442,  3088.82069587,\n",
       "       -2109.84932552,    39.58273405,   -19.14866452,   120.17876614,\n",
       "        -384.71015004,   309.34687953,   223.01770159,  -207.70846179,\n",
       "       -5561.80023737])"
      ]
     },
     "execution_count": 20,
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct the 1st Waldo image in the input matrix \"data\"\n",
<<<<<<< HEAD
    "c=C[:,i][:, np.newaxis]\n",
    "c.shape"
=======
    "c=C[:,0]\n",
    "print(c.shape)\n",
    "c\n"
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhat=U.dot(c)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139.76190476],\n",
       "       [152.42857143],\n",
       "       [116.57142857],\n",
       "       ...,\n",
       "       [124.38095238],\n",
       "       [113.76190476],\n",
       "       [242.85714286]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.02417733],\n",
       "       [111.39748629],\n",
       "       [166.        ],\n",
       "       ...,\n",
       "       [118.81020338],\n",
       "       [123.768133  ],\n",
       "       [249.19874314]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   "source": [
    "## KERNEL DIED， dimension too big?\n",
    "# Kernel didn't die on me. I got \"ValueError: cannot reshape array of size 1600000000 into shape (100,100,4)\"\n",
    "# If transpose U first, U.T.dot(c), I get \"ValueError: shapes (21,40000) and (21,) not aligned: 40000 (dim 1) != 21 (dim 0)\"\n",
<<<<<<< HEAD
    "xhat=U[:, :15].dot(c[:15, :]) + meanface\n",
    "viewimage(xhat, 100)"
=======
    "xhat=zhat + meanface\n",
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewimage(xhat,100) #reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewimage(data[:,0],100) #ori                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   f                                    ginal"
>>>>>>> e23d26bdcc08ab0ac0eec2694976beba83476d42
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Distance Function\n",
    "\n",
    " explanation and code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to Related Work?\n",
    "\n",
    "if we have time, write about existing github repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "What did you learn?  What could you do better? (What would you\n",
    "have done next if you had more time)?.....  Why do you think it didn't work if it didn't?  \n",
    "If everything worked perfectly,  what next steps would you suggest for follow-up work.  For full credit discuss two extensions or improvements to your project with short justifications for why you think that would work better (improvements) or why they are promising extensions. (approx 7 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Contribution\n",
    "| Task      | Assignee |\n",
    "| ----------- | ----------- |\n",
    "| Introduction writing     | Will       |\n",
    "| Related Work writing  | Will        |\n",
    "| Finding puzzles with answers and cropping out Waldo | Cardiff and Lilly        |\n",
    "| Vectorizing Images and methods writing   | Cardiff        |\n",
    "| PCA and methods writing      | Sara       |\n",
    "| Reconstruction Distance Function and methods writing   | Lilly and Taha        |\n",
    "| Comparison to Related Work writing      |    []    |\n",
    "| Discussion writing  |  all     |\n",
    "| Editing | all |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"relatedwork\"></a>1.[^](#relatedwork): last name, first name. (year). name of article. article link<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a8e84e92a9047c5e1f92d8b75e5225db6346aa8f60b8ab121598a6d81c0a2c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
